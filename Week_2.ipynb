{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx3IP7j8y8bIenMXuQ8zOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoyasirguroh/Ejuket_DS_ML/blob/main/Week_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to Pandas, Series, and DataFrames\n",
        "\n",
        "#### Goal:\n",
        "Familiarize  with the Pandas library and its core data structures: Series and DataFrames.\n"
      ],
      "metadata": {
        "id": "KZYZzEP1Xd-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1. Overview of Pandas and Its Applications in Data Science\n",
        " Pandas is a powerful library for data manipulation and analysis in Python.\n",
        " It provides two key data structures:\n",
        " - **Series**: One-dimensional labeled arrays.\n",
        " - **DataFrame**: Two-dimensional labeled data structures (like a table).\n",
        "\n",
        " Pandas is widely used in data preprocessing, cleaning, and exploratory data analysis (EDA).\n"
      ],
      "metadata": {
        "id": "wpCtjj-NXmyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Importing the Pandas library\n"
      ],
      "metadata": {
        "id": "Hfir_En9Xym5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 2. Series\n",
        " A Pandas Series is a one-dimensional array with labels (called the index). It can hold data of any type (integer, float, string, etc.).\n",
        "\n",
        "#### a) Creating a Series\n",
        " Let's create a Series from a Python list."
      ],
      "metadata": {
        "id": "ivXsa4glX0iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "temperatures = [30, 35, 28, 32, 31]  # Example temperature data\n",
        "temp_series = pd.Series(temperatures, index=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"])\n",
        "print(\"Temperature Series:\")\n",
        "print(temp_series)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8TB_G7rX9KE",
        "outputId": "19bf9749-4ecb-4d62-edc0-64805c82d55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature Series:\n",
            "Mon    30\n",
            "Tue    35\n",
            "Wed    28\n",
            "Thu    32\n",
            "Fri    31\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### b) Accessing Elements by Index\n",
        " You can access elements of a Series using:\n",
        " - Label-based indexing\n",
        " - Position-based indexing"
      ],
      "metadata": {
        "id": "uiPi1mHAX-Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example: Accessing elements\n",
        "print(\"\\nTemperature on Monday:\", temp_series[\"Mon\"])  # By label\n",
        "print(\"Temperature on Friday:\", temp_series[-1])  # By position\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQIfMjciYGJP",
        "outputId": "7a82db88-039e-4573-d32b-66f752a20d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature on Monday: 30\n",
            "Temperature on Friday: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c8dd796bed23>:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  print(\"Temperature on Friday:\", temp_series[-1])  # By position\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c) Operations on Series\n",
        "You can perform element-wise operations on Series, like adding, subtracting, or applying functions.\n",
        "\n",
        " Example: Element-wise operation"
      ],
      "metadata": {
        "id": "bN-afmh7YJg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Temperature Series:\")\n",
        "print(temp_series)\n",
        "adjusted_temps = temp_series + 2  # Add 2 degrees to each temperature\n",
        "print(\"\\nAdjusted Temperatures:\")\n",
        "print(adjusted_temps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfygaxGbYPWe",
        "outputId": "3077b88a-6175-4590-a4cd-2627c10d7558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature Series:\n",
            "Mon    30\n",
            "Tue    35\n",
            "Wed    28\n",
            "Thu    32\n",
            "Fri    31\n",
            "dtype: int64\n",
            "\n",
            "Adjusted Temperatures:\n",
            "Mon    32\n",
            "Tue    37\n",
            "Wed    30\n",
            "Thu    34\n",
            "Fri    33\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 3. DataFrames\n",
        " A DataFrame is a two-dimensional data structure with rows and columns, similar to a table in Excel.\n"
      ],
      "metadata": {
        "id": "iwrG6aLXYXkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### a) Creating DataFrames\n",
        " DataFrames can be created from dictionaries, lists, or files (e.g., CSV/Excel).\n",
        "\n",
        " Example: Creating a DataFrame from a dictionary"
      ],
      "metadata": {
        "id": "M3pUOrt2YcLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
        "    \"Age\": [25, 30, 35, 40],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"\\nDataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cf6KUOIYhDa",
        "outputId": "545b0f4e-ab01-4f80-8ac4-796ef5d84339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2  Charlie   35      Chicago\n",
            "3    David   40      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b) Accessing Rows, Columns, and Specific Values\n",
        " You can access rows and columns in a DataFrame using labels or indices.\n",
        "\n",
        " Example: Accessing rows and columns"
      ],
      "metadata": {
        "id": "LIxTx3b1YjIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAccessing the 'Name' column:\")\n",
        "print(df[\"Name\"])  # Accessing a column by name\n",
        "\n",
        "print(\"\\nAccessing the first row:\")\n",
        "print(df.iloc[0])  # Accessing a row by position\n",
        "\n",
        "print(\"\\nAccessing a specific value:\")\n",
        "print(df.at[2, \"City\"])  # Accessing by row index and column label\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPEOJVC_YoW0",
        "outputId": "0df7ba99-726a-4a59-bf66-f854b45a0e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accessing the 'Name' column:\n",
            "0      Alice\n",
            "1        Bob\n",
            "2    Charlie\n",
            "3      David\n",
            "Name: Name, dtype: object\n",
            "\n",
            "Accessing the first row:\n",
            "Name       Alice\n",
            "Age           25\n",
            "City    New York\n",
            "Name: 0, dtype: object\n",
            "\n",
            "Accessing a specific value:\n",
            "Chicago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c) Loading DataFrames from Files\n",
        " In Google Colab, you can upload files using the `files` module.\n"
      ],
      "metadata": {
        "id": "mI024ardYtN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Upload a file\n",
        "# Uncomment the following line to upload a CSV file manually\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Example: Loading a CSV file (assuming you uploaded 'data.csv')\n",
        "df_csv = pd.read_csv(\"Data.csv\",encoding= 'unicode_escape')\n",
        "print(\"\\nLoaded DataFrame:\")\n",
        "print(df_csv.head())  # Display the first 5 rows\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Ow5DLdHGYxkV",
        "outputId": "500c69ff-e2a2-4600-fb50-abfd7aa1e541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fdd4dd86-22c8-4123-a5c4-928ef90f48a3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fdd4dd86-22c8-4123-a5c4-928ef90f48a3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data.csv to Data (3).csv\n",
            "\n",
            "Loaded DataFrame:\n",
            "   1   Eldon Base for stackable storage shelf, platinum Muhammed MacIntyre  \\\n",
            "0  2  1.7 Cubic Foot Compact \"Cube\" Office Refrigera...       Barry French   \n",
            "1  3   Cardinal Slant-D® Ring Binder, Heavy Gauge Vinyl       Barry French   \n",
            "2  4                                               R380      Clay Rozendal   \n",
            "3  5                           Holmes HEPA Air Purifier     Carlos Soltero   \n",
            "4  6  G.E. Longer-Life Indoor Recessed Floodlight Bulbs     Carlos Soltero   \n",
            "\n",
            "     3  -213.25   38.94     35  Nunavut          Storage & Organization   0.8  \n",
            "0  293   457.81  208.16  68.02  Nunavut                      Appliances  0.58  \n",
            "1  293    46.71    8.69   2.99  Nunavut  Binders and Binder Accessories  0.39  \n",
            "2  483  1198.97  195.99   3.99  Nunavut    Telephones and Communication  0.58  \n",
            "3  515    30.94   21.78   5.94  Nunavut                      Appliances  0.50  \n",
            "4  515     4.43    6.64   4.95  Nunavut              Office Furnishings  0.37  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### d) Using Built-in Datasets\n",
        " For convenience, let's use the Titanic dataset from seaborn."
      ],
      "metadata": {
        "id": "Z8TBKzPGZDPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "titanic = sns.load_dataset(\"titanic\")  # Load Titanic dataset\n",
        "print(\"\\nFirst 5 rows of the Titanic dataset:\")\n",
        "print(titanic.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrxa0OW5ZHfy",
        "outputId": "e8fd13d6-1a60-4d85-8471-311fc997f133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 rows of the Titanic dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### e) Basic Operations on DataFrames\n",
        " DataFrames come with several handy methods for exploration and analysis.\n",
        "\n",
        " Example: Basic operations"
      ],
      "metadata": {
        "id": "VE9L7HWOZJ-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBasic Information about the Titanic DataFrame:\")\n",
        "print(titanic.info())  # Summary of the DataFrame\n",
        "\n",
        "print(\"\\nSummary Statistics of Numeric Columns:\")\n",
        "print(titanic.describe())  # Summary statistics for numeric columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQyy6xbSZN7U",
        "outputId": "03e42316-78b0-4362-f04c-6b14e5143618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Basic Information about the Titanic DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   survived     891 non-null    int64   \n",
            " 1   pclass       891 non-null    int64   \n",
            " 2   sex          891 non-null    object  \n",
            " 3   age          714 non-null    float64 \n",
            " 4   sibsp        891 non-null    int64   \n",
            " 5   parch        891 non-null    int64   \n",
            " 6   fare         891 non-null    float64 \n",
            " 7   embarked     889 non-null    object  \n",
            " 8   class        891 non-null    category\n",
            " 9   who          891 non-null    object  \n",
            " 10  adult_male   891 non-null    bool    \n",
            " 11  deck         203 non-null    category\n",
            " 12  embark_town  889 non-null    object  \n",
            " 13  alive        891 non-null    object  \n",
            " 14  alone        891 non-null    bool    \n",
            "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
            "memory usage: 80.7+ KB\n",
            "None\n",
            "\n",
            "Summary Statistics of Numeric Columns:\n",
            "         survived      pclass         age       sibsp       parch        fare\n",
            "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
            "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
            "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
            "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
            "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
            "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
            "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
            "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "temperatures = pd.Series([22, 24, 21, 20, 23, 25, 22])\n",
        "average_temperature = temperatures.mean()\n",
        "print(\"Average temperature:\", average_temperature)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Weuet0EmS8vl",
        "outputId": "a60c68c2-cdc2-4141-ea5e-62413eea2021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average temperature: 22.428571428571427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Practice Exercises\n",
        "\n",
        "#### Exercise 1: Create a Series with Temperatures and Calculate Their Average\n",
        " - Create a Series of 7 temperatures (e.g., one for each day of the week).\n",
        " - Calculate the average temperature using the `.mean()` method.\n",
        "\n",
        " Solution:"
      ],
      "metadata": {
        "id": "oyy7nsqrZQgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temps = pd.Series([29, 31, 28, 33, 30, 27, 32], index=[\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"])\n",
        "print(\"\\nTemperature Series:\")\n",
        "print(temps)\n",
        "print(\"Average Temperature:\", temps.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYr17OfcZWAw",
        "outputId": "b40fec51-cdaa-4b01-989a-a714ae1f5fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature Series:\n",
            "Sun    29\n",
            "Mon    31\n",
            "Tue    28\n",
            "Wed    33\n",
            "Thu    30\n",
            "Fri    27\n",
            "Sat    32\n",
            "dtype: int64\n",
            "Average Temperature: 30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "temp= pd.Series([30, 32, 28, 29, 31, 33, 30], index=['Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat', 'Sun'])\n",
        "avg_temp = temp.mean()\n",
        "print(\"Temperatures for the week:\")\n",
        "print(temp)\n",
        "print(f\"\\nAverage temperature: {avg_temp:.2f}°C\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB6VLpeqTOUk",
        "outputId": "3e0f042d-ac02-4fca-f529-a16c27d7030c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperatures for the week:\n",
            "Mon     30\n",
            "Tue     32\n",
            "Wed     28\n",
            "Thur    29\n",
            "Fri     31\n",
            "Sat     33\n",
            "Sun     30\n",
            "dtype: int64\n",
            "\n",
            "Average temperature: 30.43°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "temperatures = pd.Series([37,28,29,26,27,35,39])\n",
        "average_tempetarure = temperatures.mean()\n",
        "print(\"Temparature for the week:\")\n",
        "print(temp)\n",
        "print(f\"\\n average temperature: {avg_temp:.3f}°C\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQZPkAatUQvI",
        "outputId": "eaab06b9-4031-4cb2-f417-b25c535c20ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temparature for the week:\n",
            "Mon     30\n",
            "Tue     32\n",
            "Wed     28\n",
            "Thur    29\n",
            "Fri     31\n",
            "Sat     33\n",
            "Sun     30\n",
            "dtype: int64\n",
            "\n",
            " average temperature: 30.429°C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "titanic = sns.load_dataset('titanic')\n",
        "print(titanic.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwOEsw-vUrPv",
        "outputId": "f83639eb-a626-44f6-d78d-a1030688a143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
            "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
            "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
            "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
            "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "5    man        True  NaN   Queenstown    no   True  \n",
            "6    man        True    E  Southampton    no   True  \n",
            "7  child       False  NaN  Southampton    no  False  \n",
            "8  woman       False  NaN  Southampton   yes  False  \n",
            "9  child       False  NaN    Cherbourg   yes  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load Titanic dataset\n",
        "\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# Display first 10 rows\n",
        "print(titanic.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD5_rZvxU0dX",
        "outputId": "96374115-bc24-4ee1-80ac-7b7caa7c730f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
            "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
            "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
            "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
            "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "5    man        True  NaN   Queenstown    no   True  \n",
            "6    man        True    E  Southampton    no   True  \n",
            "7  child       False  NaN  Southampton    no  False  \n",
            "8  woman       False  NaN  Southampton   yes  False  \n",
            "9  child       False  NaN    Cherbourg   yes  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "boat = sns.load_dataset('titanic')\n",
        "print(boat.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyFBNL8fU65m",
        "outputId": "24b7e902-8703-411b-8031-684cfcec56f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
            "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
            "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
            "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
            "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "5    man        True  NaN   Queenstown    no   True  \n",
            "6    man        True    E  Southampton    no   True  \n",
            "7  child       False  NaN  Southampton    no  False  \n",
            "8  woman       False  NaN  Southampton   yes  False  \n",
            "9  child       False  NaN    Cherbourg   yes  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "titanic = sns.load_dataset('titanic')\n",
        "print(titanic.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys8BF9XQVRNN",
        "outputId": "70f064db-bb3a-4e9f-a278-bf47bd6f54db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
            "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
            "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
            "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
            "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "5    man        True  NaN   Queenstown    no   True  \n",
            "6    man        True    E  Southampton    no   True  \n",
            "7  child       False  NaN  Southampton    no  False  \n",
            "8  woman       False  NaN  Southampton   yes  False  \n",
            "9  child       False  NaN    Cherbourg   yes  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Exercise 2: Load a Dataset and Display the First 10 Rows\n",
        " - Load the Titanic dataset (or another dataset of your choice) using seaborn.\n",
        " - Display the first 10 rows using.\n",
        "\n",
        " Solution:"
      ],
      "metadata": {
        "id": "qibwkzinZYBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 10 rows of the Titanic dataset:\")\n",
        "print(titanic.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frSuWTflZdwG",
        "outputId": "c4d82fe3-1371-46d3-dd17-f5517cbc2a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 10 rows of the Titanic dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
            "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
            "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
            "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
            "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
            "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "5    man        True  NaN   Queenstown    no   True  \n",
            "6    man        True    E  Southampton    no   True  \n",
            "7  child       False  NaN  Southampton    no  False  \n",
            "8  woman       False  NaN  Southampton   yes  False  \n",
            "9  child       False  NaN    Cherbourg   yes  False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic_name_age = titanic[['sex', 'age']]\n",
        "age_stats = titanic_name_age['age'].describe()\n",
        "print(\"Extracted Name and Age columns:\")\n",
        "print(titanic_name_age.head())\n",
        "\n",
        "print(\"\\nBasic Statistics for 'Age' column:\")\n",
        "print(age_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6OJ9Z2WyIX",
        "outputId": "709b9688-5a34-470e-e3ed-4624fb6ba58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Name and Age columns:\n",
            "      sex   age\n",
            "0    male  22.0\n",
            "1  female  38.0\n",
            "2  female  26.0\n",
            "3  female  35.0\n",
            "4    male  35.0\n",
            "\n",
            "Basic Statistics for 'Age' column:\n",
            "count    714.000000\n",
            "mean      29.699118\n",
            "std       14.526497\n",
            "min        0.420000\n",
            "25%       20.125000\n",
            "50%       28.000000\n",
            "75%       38.000000\n",
            "max       80.000000\n",
            "Name: age, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "titanic = sns.load_dataset('titanic')\n",
        "name_age_df = titanic[['sex', 'age']]\n",
        "print(name_age_df.head(5))\n",
        "age_stats = titanic['age'].describe()\n",
        "print(age_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az-EelRzW2y9",
        "outputId": "8a1d5ce2-cbb5-4b9d-99d1-1f2864d1f2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      sex   age\n",
            "0    male  22.0\n",
            "1  female  38.0\n",
            "2  female  26.0\n",
            "3  female  35.0\n",
            "4    male  35.0\n",
            "count    714.000000\n",
            "mean      29.699118\n",
            "std       14.526497\n",
            "min        0.420000\n",
            "25%       20.125000\n",
            "50%       28.000000\n",
            "75%       38.000000\n",
            "max       80.000000\n",
            "Name: age, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('titanic.csv')\n",
        "extracted_data = df[['Name', 'Age']]\n",
        "print(extracted_data.head())\n",
        "age_statistics = df['Age'].describe()\n",
        "print(age_statistics)"
      ],
      "metadata": {
        "id": "eoGBd9v7XsiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Exercise 3: Extract Specific Columns and Calculate Basic Statistics\n",
        " - Extract the \"sex\" and \"age\" columns from the Titanic dataset.\n",
        " - Calculate basic statistics for the \"age\" column.\n",
        "\n",
        " Solution:"
      ],
      "metadata": {
        "id": "-y3JPUeQZiyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name_and_age = titanic[[\"sex\", \"age\"]]  # 'sex' instead of 'name' in Titanic dataset\n",
        "print(\"\\nSex and Age Columns:\")\n",
        "print(name_and_age.head())\n",
        "\n",
        "print(\"\\nBasic Statistics for Age:\")\n",
        "print(titanic[\"age\"].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umc95jnHZmrX",
        "outputId": "49c5734f-0029-455b-f47e-73b970aa5ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sex and Age Columns:\n",
            "      sex   age\n",
            "0    male  22.0\n",
            "1  female  38.0\n",
            "2  female  26.0\n",
            "3  female  35.0\n",
            "4    male  35.0\n",
            "\n",
            "Basic Statistics for Age:\n",
            "count    714.000000\n",
            "mean      29.699118\n",
            "std       14.526497\n",
            "min        0.420000\n",
            "25%       20.125000\n",
            "50%       28.000000\n",
            "75%       38.000000\n",
            "max       80.000000\n",
            "Name: age, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### Conclusion\n",
        " In this session, we explored Pandas' core data structures: Series and DataFrames.\n",
        " We learned how to create, manipulate, and analyze data using these structures. Practice these exercises to deepen your understanding of Pandas!"
      ],
      "metadata": {
        "id": "jGApVcmeZqHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Data Cleaning and Preprocessing\n",
        "\n",
        " ### Goal:\n",
        " Teach data preparation techniques for ensuring clean and structured datasets."
      ],
      "metadata": {
        "id": "i0FaZjrjZwWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5CeWc3FVZ1Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---\n",
        " ### 1. Identifying and Handling Duplicates\n",
        " Duplicate data can affect analysis and model performance. Pandas provides tools to identify and remove duplicates.\n",
        "\n",
        " #### Example: Drop Duplicate Rows\n",
        " Create a sample DataFrame with duplicate rows"
      ],
      "metadata": {
        "id": "jalyz-2kZ3U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Alice\", \"Charlie\", \"Bob\"],\n",
        "    \"Age\": [25, 30, 25, 35, 30],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"New York\", \"Chicago\", \"Los Angeles\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoMKxohFZ76Z",
        "outputId": "4aa3babb-295f-47cf-89e9-b378f06360f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "2    Alice   25     New York\n",
            "3  Charlie   35      Chicago\n",
            "4      Bob   30  Los Angeles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify duplicates using .duplicated()\n",
        "print(\"\\nDuplicate Rows (True means duplicate):\")\n",
        "print(df.duplicated())\n",
        "\n",
        "# Remove duplicate rows using .drop_duplicates()\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "print(\"\\nDataFrame after removing duplicates:\")\n",
        "print(df_no_duplicates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKc2CK8jaBMj",
        "outputId": "9fa2c32b-70fc-4757-e917-bdf4cd63dcc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Duplicate Rows (True means duplicate):\n",
            "0    False\n",
            "1    False\n",
            "2     True\n",
            "3    False\n",
            "4     True\n",
            "dtype: bool\n",
            "\n",
            "DataFrame after removing duplicates:\n",
            "      Name  Age         City\n",
            "0    Alice   25     New York\n",
            "1      Bob   30  Los Angeles\n",
            "3  Charlie   35      Chicago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 2. Renaming Columns and Reindexing\n",
        " Renaming columns is helpful for clarity and consistency.\n",
        "\n",
        " #### Example: Rename Columns\n",
        " Rename columns using the .rename() method"
      ],
      "metadata": {
        "id": "c0WCjb-MaDS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed = df_no_duplicates.rename(columns={\"Name\": \"Full Name\", \"Age\": \"Age (Years)\"})\n",
        "print(\"\\nDataFrame with Renamed Columns:\")\n",
        "print(df_renamed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQbySOXGaIqV",
        "outputId": "ae353e43-e425-42f4-a4b9-1c055ca0a7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Renamed Columns:\n",
            "  Full Name  Age (Years)         City\n",
            "0     Alice           25     New York\n",
            "1       Bob           30  Los Angeles\n",
            "3   Charlie           35      Chicago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example: Reindexing Rows\n",
        " Reindexing resets the row indices in a DataFrame"
      ],
      "metadata": {
        "id": "-4gxGaBKaKiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_duplicates = df_no_duplicates.set_index('Name')\n",
        "df_no_duplicates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "w9uTPPuGc6hB",
        "outputId": "86350244-2085-4c07-d4c2-3da0b3dc2413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Age         City\n",
              "Name                     \n",
              "Alice     25     New York\n",
              "Bob       30  Los Angeles\n",
              "Charlie   35      Chicago"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-085e9065-bba6-4997-8600-daa82d7a2b4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>City</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alice</th>\n",
              "      <td>25</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bob</th>\n",
              "      <td>30</td>\n",
              "      <td>Los Angeles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Charlie</th>\n",
              "      <td>35</td>\n",
              "      <td>Chicago</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-085e9065-bba6-4997-8600-daa82d7a2b4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-085e9065-bba6-4997-8600-daa82d7a2b4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-085e9065-bba6-4997-8600-daa82d7a2b4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-552c8672-ea23-4b7b-9920-b31a47278bc6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-552c8672-ea23-4b7b-9920-b31a47278bc6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-552c8672-ea23-4b7b-9920-b31a47278bc6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e90254fd-7186-4ca3-a88c-8b96860c9db6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_no_duplicates')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e90254fd-7186-4ca3-a88c-8b96860c9db6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_no_duplicates');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_no_duplicates",
              "summary": "{\n  \"name\": \"df_no_duplicates\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Alice\",\n          \"Bob\",\n          \"Charlie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 25,\n        \"max\": 35,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          25,\n          30,\n          35\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"City\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"New York\",\n          \"Los Angeles\",\n          \"Chicago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_duplicates = df_no_duplicates.set_index('Name')\n",
        "df_no_duplicates\n",
        "df_reindexed = df_no_duplicates.reset_index(drop=True)\n",
        "print(\"\\nDataFrame with Reindexed Rows:\")\n",
        "print(df_reindexed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH8j5Y_AaNv0",
        "outputId": "61f269c1-b255-4783-e114-15a67f87725a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Reindexed Rows:\n",
            "   Age         City\n",
            "0   25     New York\n",
            "1   30  Los Angeles\n",
            "2   35      Chicago\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 3. Data Type Conversions\n",
        " DataFrames often have columns with incorrect data types. For example, numbers stored as strings or dates stored as objects.\n",
        " #### Example: Convert Strings to Numeric\n",
        " Create a DataFrame with a column of strings representing numbers"
      ],
      "metadata": {
        "id": "w4dyuz5JaTr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_strings = {\n",
        "    \"ID\": [1, 2, 3],\n",
        "    \"Value\": [\"100\", \"200\", \"NaN\"]\n",
        "}\n",
        "df_strings = pd.DataFrame(data_with_strings)\n",
        "print(\"\\nDataFrame with String Values:\")\n",
        "print(df_strings)\n",
        "print(df_strings.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_feGm9saYsg",
        "outputId": "8ed92607-0788-42a7-af67-637df8843a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with String Values:\n",
            "   ID Value\n",
            "0   1   100\n",
            "1   2   200\n",
            "2   3   NaN\n",
            "ID        int64\n",
            "Value    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the \"Value\" column to numeric using pd.to_numeric()\n",
        "df_strings[\"Value\"] = pd.to_numeric(df_strings[\"Value\"], errors=\"coerce\")\n",
        "print(\"\\nDataFrame after Converting 'Value' to Numeric:\")\n",
        "print(df_strings)\n",
        "print(df_strings.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LRgk279aaeC",
        "outputId": "be76a53d-7050-4658-d122-4c4fc46a48c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Converting 'Value' to Numeric:\n",
            "   ID  Value\n",
            "0   1  100.0\n",
            "1   2  200.0\n",
            "2   3    NaN\n",
            "ID         int64\n",
            "Value    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #### Example: Convert Strings to Datetime\n",
        " Create a DataFrame with dates stored as strings"
      ],
      "metadata": {
        "id": "kvu6bTIladBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_dates = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Join Date\": [\"2023-01-15\", \"2023-05-20\", \"2023-07-01\"]\n",
        "}\n",
        "df_dates = pd.DataFrame(data_with_dates)\n",
        "print(\"\\nDataFrame with Date Strings:\")\n",
        "print(df_dates)\n",
        "print(df_dates.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlqJqVJaagyK",
        "outputId": "362ec06d-bdd0-4f95-a4ec-7ad4c4844784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Date Strings:\n",
            "      Name   Join Date\n",
            "0    Alice  2023-01-15\n",
            "1      Bob  2023-05-20\n",
            "2  Charlie  2023-07-01\n",
            "Name         object\n",
            "Join Date    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the \"Join Date\" column to datetime\n",
        "df_dates[\"Join Date\"] = pd.to_datetime(df_dates[\"Join Date\"])\n",
        "print(\"\\nDataFrame after Converting 'Join Date' to Datetime:\")\n",
        "print(df_dates)\n",
        "print(df_dates.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atw1V1JYaieu",
        "outputId": "dccdc03c-46d7-47c9-a0b8-b930bc8c884d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Converting 'Join Date' to Datetime:\n",
            "      Name  Join Date\n",
            "0    Alice 2023-01-15\n",
            "1      Bob 2023-05-20\n",
            "2  Charlie 2023-07-01\n",
            "Name                 object\n",
            "Join Date    datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 4. Dropping Unnecessary Columns or Rows\n",
        " Sometimes, certain columns or rows do not contribute to the analysis and need to be removed.\n",
        "\n",
        " #### Example: Drop Columns\n",
        " Drop the \"City\" column from the original DataFrame"
      ],
      "metadata": {
        "id": "r5ONA-tRaknb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped_columns = df_no_duplicates.drop(columns=[\"City\"])\n",
        "print(\"\\nDataFrame after Dropping 'City' Column:\")\n",
        "print(df_dropped_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3Hj66X7ao9x",
        "outputId": "01b9a548-0ecc-4a4a-8742-ec895fd7f9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Dropping 'City' Column:\n",
            "         Age\n",
            "Name        \n",
            "Alice     25\n",
            "Bob       30\n",
            "Charlie   35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Example: Drop Rows with Missing Values\n",
        " Create a sample DataFrame with missing values"
      ],
      "metadata": {
        "id": "YgVgXhjv8ASb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_missing = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", np.nan, \"David\"],\n",
        "    \"Age\": [25, 30, np.nan, 40],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\", np.nan]\n",
        "}\n",
        "df_missing = pd.DataFrame(data_with_missing)\n",
        "print(\"\\nDataFrame with Missing Values:\")\n",
        "print(df_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCs8hL8y8R4w",
        "outputId": "a8b9aa6b-712a-41a5-cbd0-dbe9f8dfe93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Missing Values:\n",
            "    Name   Age         City\n",
            "0  Alice  25.0     New York\n",
            "1    Bob  30.0  Los Angeles\n",
            "2    NaN   NaN      Chicago\n",
            "3  David  40.0          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop rows with missing values\n",
        "df_no_missing = df_missing.dropna()\n",
        "print(\"\\nDataFrame after Dropping Rows with Missing Values:\")\n",
        "print(df_no_missing)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es_TTKUr8Urq",
        "outputId": "cfa294d3-8e41-4f2c-d81a-eabeab445404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Dropping Rows with Missing Values:\n",
            "    Name   Age         City\n",
            "0  Alice  25.0     New York\n",
            "1    Bob  30.0  Los Angeles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "titanic = sns.load_dataset('titanic')\n",
        "duplicates = titanic.duplicated()\n",
        "print(f\"Number of duplicate rows: {duplicates.sum()}\")\n",
        "titanic_cleaned = titanic.drop_duplicates()\n",
        "print(titanic_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MB3_tmdhxaD",
        "outputId": "37a6c510-e9bf-4ac5-9fbd-8c31723acfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 107\n",
            "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0           0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1           1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2           1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3           1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4           0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "..        ...     ...     ...   ...    ...    ...      ...      ...    ...   \n",
            "885         0       3  female  39.0      0      5  29.1250        Q  Third   \n",
            "887         1       1  female  19.0      0      0  30.0000        S  First   \n",
            "888         0       3  female   NaN      1      2  23.4500        S  Third   \n",
            "889         1       1    male  26.0      0      0  30.0000        C  First   \n",
            "890         0       3    male  32.0      0      0   7.7500        Q  Third   \n",
            "\n",
            "       who  adult_male deck  embark_town alive  alone  \n",
            "0      man        True  NaN  Southampton    no  False  \n",
            "1    woman       False    C    Cherbourg   yes  False  \n",
            "2    woman       False  NaN  Southampton   yes   True  \n",
            "3    woman       False    C  Southampton   yes  False  \n",
            "4      man        True  NaN  Southampton    no   True  \n",
            "..     ...         ...  ...          ...   ...    ...  \n",
            "885  woman       False  NaN   Queenstown    no  False  \n",
            "887  woman       False    B  Southampton   yes   True  \n",
            "888  woman       False  NaN  Southampton    no  False  \n",
            "889    man        True    C    Cherbourg   yes   True  \n",
            "890    man        True  NaN   Queenstown    no   True  \n",
            "\n",
            "[784 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df = sns.load_dataset('titanic')\n",
        "print(\"Original dataset:\")\n",
        "print(df.head())\n",
        "duplicates = df[df.duplicated()]\n",
        "print(\"\\nDuplicate rows:\")\n",
        "print(duplicates)\n",
        "df_cleaned = df.drop_duplicates()\n",
        "print(\"\\nDataset after removing duplicates:\")\n",
        "print(df_cleaned.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tux1TD-ah5ia",
        "outputId": "63d0f66f-e311-47a6-b875-5b155d9fcf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "\n",
            "Duplicate rows:\n",
            "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
            "47          1       3  female   NaN      0      0   7.7500        Q   Third   \n",
            "76          0       3    male   NaN      0      0   7.8958        S   Third   \n",
            "77          0       3    male   NaN      0      0   8.0500        S   Third   \n",
            "87          0       3    male   NaN      0      0   8.0500        S   Third   \n",
            "95          0       3    male   NaN      0      0   8.0500        S   Third   \n",
            "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
            "870         0       3    male  26.0      0      0   7.8958        S   Third   \n",
            "877         0       3    male  19.0      0      0   7.8958        S   Third   \n",
            "878         0       3    male   NaN      0      0   7.8958        S   Third   \n",
            "884         0       3    male  25.0      0      0   7.0500        S   Third   \n",
            "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
            "\n",
            "       who  adult_male deck  embark_town alive  alone  \n",
            "47   woman       False  NaN   Queenstown   yes   True  \n",
            "76     man        True  NaN  Southampton    no   True  \n",
            "77     man        True  NaN  Southampton    no   True  \n",
            "87     man        True  NaN  Southampton    no   True  \n",
            "95     man        True  NaN  Southampton    no   True  \n",
            "..     ...         ...  ...          ...   ...    ...  \n",
            "870    man        True  NaN  Southampton    no   True  \n",
            "877    man        True  NaN  Southampton    no   True  \n",
            "878    man        True  NaN  Southampton    no   True  \n",
            "884    man        True  NaN  Southampton    no   True  \n",
            "886    man        True  NaN  Southampton    no   True  \n",
            "\n",
            "[107 rows x 15 columns]\n",
            "\n",
            "Dataset after removing duplicates:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ---\n",
        " ### Practice Exercises\n",
        "\n",
        " #### Exercise 1: Identify Duplicate Rows and Remove Them\n",
        " - Load the Titanic dataset from seaborn.\n",
        " - Identify duplicate rows in the dataset and remove them.\n"
      ],
      "metadata": {
        "id": "qD1GL_nl8W62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "U6ssqUpu8hO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "print(\"\\nTitanic Dataset:\")\n",
        "print(titanic.head())\n",
        "\n",
        "# Identify duplicates\n",
        "duplicates = titanic.duplicated()\n",
        "print(\"\\nNumber of Duplicate Rows in Titanic Dataset:\", duplicates.sum())\n",
        "\n",
        "# Remove duplicates\n",
        "titanic_no_duplicates = titanic.drop_duplicates()\n",
        "print(\"\\nTitanic Dataset after Removing Duplicates:\")\n",
        "print(titanic_no_duplicates.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gia6E2AX8lnb",
        "outputId": "dd4f6b7e-87c6-4604-fc19-f9e2cca47b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Titanic Dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "\n",
            "Number of Duplicate Rows in Titanic Dataset: 107\n",
            "\n",
            "Titanic Dataset after Removing Duplicates:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df = sns.load_dataset('titanic')\n",
        "df.rename(columns={'embark_town': 'Embarkation Town', 'fare': 'Ticket Fare'}, inplace=True)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1nCU6fQjcng",
        "outputId": "ebbfc6fc-0630-46d5-b3d3-603f61b39ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch  Ticket Fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0       7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0      71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0       7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0      53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0       8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck Embarkation Town alive  alone  \n",
            "0    man        True  NaN      Southampton    no  False  \n",
            "1  woman       False    C        Cherbourg   yes  False  \n",
            "2  woman       False  NaN      Southampton   yes   True  \n",
            "3  woman       False    C      Southampton   yes  False  \n",
            "4    man        True  NaN      Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyBs0XSpjjRf",
        "outputId": "0e918b87-4a96-422b-f693-f800e80fc515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'Ticket Fare',\n",
            "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
            "       'alive', 'alone'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Exercise 2: Rename Columns in the Titanic Dataset\n",
        " - Rename the \"embark_town\" column to \"Embarkation Town\".\n",
        " - Rename the \"fare\" column to \"Ticket Fare\".\n"
      ],
      "metadata": {
        "id": "isfGwCCS8ofQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_renamed = titanic.rename(columns={\"embark_town\": \"Embarkation Town\", \"fare\": \"Ticket Fare\"})\n",
        "print(\"\\nTitanic Dataset with Renamed Columns:\")\n",
        "print(titanic_renamed.head())\n"
      ],
      "metadata": {
        "id": "xSWQG2238wJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "date_data = {\n",
        "    \"Event\": [\"Event A\", \"Event B\", \"Event C\"],\n",
        "    \"Date\": [\"2024-01-01\", \"2023-12-25\", \"2024-07-04\"]\n",
        "}\n",
        "df = pd.DataFrame(date_data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "print(df)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omw4gmEOk-cV",
        "outputId": "7cb2adc6-9f3a-48af-d23c-173095171759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Event       Date  Year\n",
            "0  Event A 2024-01-01  2024\n",
            "1  Event B 2023-12-25  2023\n",
            "2  Event C 2024-07-04  2024\n",
            "Event            object\n",
            "Date     datetime64[ns]\n",
            "Year              int32\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "date_data = {\n",
        "    \"Event\": [\"Event A\", \"Event B\", \"Event C\"],\n",
        "    \"Date\": [\"2024-01-01\", \"2023-12-25\", \"2024-07-04\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(date_data)\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "print(df)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqc3l03-lI7h",
        "outputId": "1499992e-8a10-48b5-9cec-e70fbe78cda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Event       Date  Year\n",
            "0  Event A 2024-01-01  2024\n",
            "1  Event B 2023-12-25  2023\n",
            "2  Event C 2024-07-04  2024\n",
            "Event            object\n",
            "Date     datetime64[ns]\n",
            "Year              int32\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Exercise 3: Convert a Column to Datetime Format\n",
        " - Load a dataset with a column of dates stored as strings.\n",
        " - Convert the column to `datetime` format and extract the year.\n",
        "\n",
        " Create a small dataset with dates stored as strings"
      ],
      "metadata": {
        "id": "n8DY0qGQ8yUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_data = {\n",
        "    \"Event\": [\"Event A\", \"Event B\", \"Event C\"],\n",
        "    \"Date\": [\"2024-01-01\", \"2023-12-25\", \"2024-07-04\"]\n",
        "}\n",
        "df_event_dates = pd.DataFrame(date_data)\n",
        "print(\"\\nDataset with Dates as Strings:\")\n",
        "print(df_event_dates)"
      ],
      "metadata": {
        "id": "v3SXA_es89h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Conclusion\n",
        " In this session, we covered data cleaning and preprocessing techniques, including handling duplicates, renaming columns, converting data types, and dropping unnecessary data. These techniques are crucial for preparing datasets for analysis and modeling.\n"
      ],
      "metadata": {
        "id": "ZgRIEQWd9E23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Handling Missing Data\n",
        " ### Goal:\n",
        " Understand strategies to deal with missing or incomplete data.\n"
      ],
      "metadata": {
        "id": "PTTgHEhs9NqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "F7EZXnGk8_w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 1. Identifying Missing Values\n",
        " Missing values can significantly impact data analysis and modeling. Identifying them is the first step.\n",
        "\n",
        " #### Example: Detect Missing Values\n",
        " Create a sample DataFrame with missing values"
      ],
      "metadata": {
        "id": "KxuLPYGn9WG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
        "    \"Age\": [25, np.nan, 35, 40, np.nan],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", np.nan, \"Chicago\", \"Houston\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "23zz8ObcW13H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32bbca35-29c3-40f1-b5f7-0f5bebd71884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "      Name   Age         City\n",
            "0    Alice  25.0     New York\n",
            "1      Bob   NaN  Los Angeles\n",
            "2  Charlie  35.0          NaN\n",
            "3    David  40.0      Chicago\n",
            "4      Eve   NaN      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use isnull() to detect missing values\n",
        "print(\"\\nMissing Values (True indicates missing):\")\n",
        "print(df.isnull())\n",
        "\n",
        "# Use notnull() to detect non-missing values\n",
        "print(\"\\nNon-Missing Values (True indicates present):\")\n",
        "print(df.notnull())"
      ],
      "metadata": {
        "id": "kNBsxz6B9fm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d044098-b44a-4b17-b8a5-7208cf57e6e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values (True indicates missing):\n",
            "    Name    Age   City\n",
            "0  False  False  False\n",
            "1  False   True  False\n",
            "2  False  False   True\n",
            "3  False  False  False\n",
            "4  False   True  False\n",
            "\n",
            "Non-Missing Values (True indicates present):\n",
            "   Name    Age   City\n",
            "0  True   True   True\n",
            "1  True  False   True\n",
            "2  True   True  False\n",
            "3  True   True   True\n",
            "4  True  False   True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### 2. Filling Missing Values\n",
        " Replace missing values with placeholders or meaningful values.\n",
        "\n",
        " #### Example: Fill Missing Values with a Placeholder"
      ],
      "metadata": {
        "id": "UXPdF2It9h_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filled_placeholder = df.fillna(\"Unknown\")\n",
        "print(\"\\nDataFrame with Missing Values Replaced by 'Unknown':\")\n",
        "print(df_filled_placeholder)\n"
      ],
      "metadata": {
        "id": "bhaEl4xs9qRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1615ed39-bb79-4bf9-f3e8-a9300b843c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Missing Values Replaced by 'Unknown':\n",
            "      Name      Age         City\n",
            "0    Alice     25.0     New York\n",
            "1      Bob  Unknown  Los Angeles\n",
            "2  Charlie     35.0      Unknown\n",
            "3    David     40.0      Chicago\n",
            "4      Eve  Unknown      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #### Example: Fill Missing Values with Column Mean\n",
        " For numeric columns, replacing with the mean is common"
      ],
      "metadata": {
        "id": "5sR-V1Ow9sue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n",
        "print(\"\\nDataFrame with Missing Ages Replaced by Mean:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "V7Jp9A8t9xU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba30ca73-6ff2-49f2-9f6d-a369a5406b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame with Missing Ages Replaced by Mean:\n",
            "      Name        Age         City\n",
            "0    Alice  25.000000     New York\n",
            "1      Bob  33.333333  Los Angeles\n",
            "2  Charlie  35.000000          NaN\n",
            "3    David  40.000000      Chicago\n",
            "4      Eve  33.333333      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### 3. Dropping Rows or Columns with Missing Data\n",
        " If a row or column has too many missing values, you can drop it.\n",
        "\n",
        " #### Example: Drop Rows with Missing Data\n",
        " Drop rows where any value is missing"
      ],
      "metadata": {
        "id": "fLTwsNf_91le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped_rows = df.dropna()\n",
        "print(\"\\nDataFrame after Dropping Rows with Missing Values:\")\n",
        "print(df_dropped_rows)\n"
      ],
      "metadata": {
        "id": "-6pm7sLM98YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a079745a-0ea2-427d-cb4a-27d83618a7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Dropping Rows with Missing Values:\n",
            "    Name        Age         City\n",
            "0  Alice  25.000000     New York\n",
            "1    Bob  33.333333  Los Angeles\n",
            "3  David  40.000000      Chicago\n",
            "4    Eve  33.333333      Houston\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Example: Drop Columns with Missing Data\n",
        " Drop columns where any value is missing"
      ],
      "metadata": {
        "id": "fvorcswv-D48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped_columns = df.dropna(axis=1)\n",
        "print(\"\\nDataFrame after Dropping Columns with Missing Values:\")\n",
        "print(df_dropped_columns)"
      ],
      "metadata": {
        "id": "zHM0gOEg-Cvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0095889-10e3-4488-ceca-d26818a11a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame after Dropping Columns with Missing Values:\n",
            "      Name        Age\n",
            "0    Alice  25.000000\n",
            "1      Bob  33.333333\n",
            "2  Charlie  35.000000\n",
            "3    David  40.000000\n",
            "4      Eve  33.333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 4. Interpolating Missing Values\n",
        " For continuous data, you can use interpolation to estimate missing values.\n",
        "\n",
        " #### Example: Interpolate Missing Values\n",
        " Create a DataFrame with missing values in a sequence"
      ],
      "metadata": {
        "id": "QG-uBhF1-Jwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_series_data = {\n",
        "    \"Day\": [1, 2, 3, 4, 5],\n",
        "    \"Temperature\": [30, np.nan, 35, np.nan, 40]\n",
        "}\n",
        "df_time_series = pd.DataFrame(time_series_data)\n",
        "print(\"\\nTime Series DataFrame with Missing Values:\")\n",
        "print(df_time_series)"
      ],
      "metadata": {
        "id": "kWtyfc_0-V6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a536cf5-0669-4fb6-9711-4fdd9cce2d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time Series DataFrame with Missing Values:\n",
            "   Day  Temperature\n",
            "0    1         30.0\n",
            "1    2          NaN\n",
            "2    3         35.0\n",
            "3    4          NaN\n",
            "4    5         40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpolate missing values\n",
        "df_time_series[\"Temperature\"] = df_time_series[\"Temperature\"].interpolate()\n",
        "print(\"\\nTime Series DataFrame after Interpolation:\")\n",
        "print(df_time_series)"
      ],
      "metadata": {
        "id": "NBj-WWhm-YE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9edcf36-4532-46e9-b86a-2c7e639763a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time Series DataFrame after Interpolation:\n",
            "   Day  Temperature\n",
            "0    1         30.0\n",
            "1    2         32.5\n",
            "2    3         35.0\n",
            "3    4         37.5\n",
            "4    5         40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# titanic = pd.read_csv('titanic.csv')\n",
        "titanic=sns.load_dataset(\"titanic\")\n",
        "missing_percentage = titanic.isnull().mean() * 100\n",
        "print(missing_percentage.sort_values(ascending=False))\n",
        "print(\"\\nCleaning Strategies:\")\n",
        "for col, perc in missing_percentage.items():\n",
        "    if perc > 50:\n",
        "        print(f\"Column '{col}' has {perc:.2f}%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm6_6p68aodz",
        "outputId": "9217acab-33f8-421e-e9e1-e0badf164391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deck           77.216611\n",
            "age            19.865320\n",
            "embarked        0.224467\n",
            "embark_town     0.224467\n",
            "survived        0.000000\n",
            "pclass          0.000000\n",
            "sex             0.000000\n",
            "sibsp           0.000000\n",
            "parch           0.000000\n",
            "fare            0.000000\n",
            "class           0.000000\n",
            "who             0.000000\n",
            "adult_male      0.000000\n",
            "alive           0.000000\n",
            "alone           0.000000\n",
            "dtype: float64\n",
            "\n",
            "Cleaning Strategies:\n",
            "Column 'deck' has 77.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Practice Exercises\n",
        "\n",
        " #### Exercise 1: Identify Percentage of Missing Data\n",
        " - Load the Titanic dataset from seaborn.\n",
        " - Calculate the percentage of missing data for each column and decide on a cleaning strategy.\n"
      ],
      "metadata": {
        "id": "DNOGVQyi-fuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "titanic = sns.load_dataset('titanic')\n",
        "missing_data_percentage =titanic.isnull().mean() * 100\n",
        "print(missing_data_percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy4pKQ6dbJQG",
        "outputId": "e6989265-d8ee-4b86-884a-b361684fc510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "survived        0.000000\n",
            "pclass          0.000000\n",
            "sex             0.000000\n",
            "age            19.865320\n",
            "sibsp           0.000000\n",
            "parch           0.000000\n",
            "fare            0.000000\n",
            "embarked        0.224467\n",
            "class           0.000000\n",
            "who             0.000000\n",
            "adult_male      0.000000\n",
            "deck           77.216611\n",
            "embark_town     0.224467\n",
            "alive           0.000000\n",
            "alone           0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "print(\"\\nTitanic Dataset:\")\n",
        "print(titanic.head())\n",
        "\n",
        "# Calculate the percentage of missing data\n",
        "missing_percentage = titanic.isnull().mean() * 100\n",
        "print(\"\\nPercentage of Missing Data in Each Column:\")\n",
        "print(missing_percentage)\n"
      ],
      "metadata": {
        "id": "xrhFdxU--fJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105c6dcb-4f43-4323-f8f4-cbde4c0deb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Titanic Dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "\n",
            "Percentage of Missing Data in Each Column:\n",
            "survived        0.000000\n",
            "pclass          0.000000\n",
            "sex             0.000000\n",
            "age            19.865320\n",
            "sibsp           0.000000\n",
            "parch           0.000000\n",
            "fare            0.000000\n",
            "embarked        0.224467\n",
            "class           0.000000\n",
            "who             0.000000\n",
            "adult_male      0.000000\n",
            "deck           77.216611\n",
            "embark_town     0.224467\n",
            "alive           0.000000\n",
            "alone           0.000000\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        " #### Exercise 2: Replace Missing Values with Median\n",
        " - Replace missing values in the \"age\" column with its median."
      ],
      "metadata": {
        "id": "ulatoTPX-oVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# titanic = pd.read_csv('titanic.csv')\n",
        "age_median = titanic['age'].median()\n",
        "titanic['age'].fillna(age_median, inplace=True)\n",
        "print(f\"Missing values in 'age': {titanic['age'].isnull().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40tPIOq_cWE6",
        "outputId": "1edc3c16-b0ed-4af3-825c-8cb594340099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'age': 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-31f6cf838d8c>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  titanic['age'].fillna(age_median, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic['age'] = titanic['age'].fillna(titanic['age'].median())\n",
        "print(titanic.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lij9j7_czFG",
        "outputId": "d0834f87-2c05-4561-d429-219716392d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titanic[\"age\"] = titanic[\"age\"].fillna(titanic[\"age\"].median())\n",
        "print(\"\\n'Titanic' Dataset after Replacing Missing 'age' with Median:\")\n",
        "print(titanic[[\"age\"]].head())\n",
        "\n"
      ],
      "metadata": {
        "id": "Rm5gEIo0XD45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91a2388-dd13-4801-9ac3-06b89134ed82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'Titanic' Dataset after Replacing Missing 'age' with Median:\n",
            "    age\n",
            "0  22.0\n",
            "1  38.0\n",
            "2  26.0\n",
            "3  35.0\n",
            "4  35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " #### Exercise 3: Interpolate Missing Values in a Time-Series Dataset\n",
        " - Create a time-series dataset with missing values and interpolate them."
      ],
      "metadata": {
        "id": "g3HidWgBaFeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "time_series_with_gaps = {\n",
        "    \"Date\": pd.date_range(start=\"2023-01-01\", periods=7),\n",
        "    \"Value\": [10, np.nan, 15, np.nan, 20, np.nan, 25]\n",
        "}\n",
        "df_time_series_with_gaps = pd.DataFrame(time_series_with_gaps)\n",
        "print(\"\\nTime-Series Data with Gaps:\")\n",
        "print(df_time_series_with_gaps)\n",
        "\n",
        "# Interpolate missing values\n",
        "df_time_series_with_gaps[\"Value\"] = df_time_series_with_gaps[\"Value\"].interpolate()\n",
        "print(\"\\nTime-Series Data after Interpolation:\")\n",
        "print(df_time_series_with_gaps)\n",
        "\n",
        "# ---"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BppEVvRcaDvy",
        "outputId": "4f78ee79-cb4c-45b2-ab50-d22c808db2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Time-Series Data with Gaps:\n",
            "        Date  Value\n",
            "0 2023-01-01   10.0\n",
            "1 2023-01-02    NaN\n",
            "2 2023-01-03   15.0\n",
            "3 2023-01-04    NaN\n",
            "4 2023-01-05   20.0\n",
            "5 2023-01-06    NaN\n",
            "6 2023-01-07   25.0\n",
            "\n",
            "Time-Series Data after Interpolation:\n",
            "        Date  Value\n",
            "0 2023-01-01   10.0\n",
            "1 2023-01-02   12.5\n",
            "2 2023-01-03   15.0\n",
            "3 2023-01-04   17.5\n",
            "4 2023-01-05   20.0\n",
            "5 2023-01-06   22.5\n",
            "6 2023-01-07   25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "time_series_with_gaps = {\n",
        "    \"Date\": pd.date_range(start=\"2023-01-01\", periods=7),\n",
        "    \"Value\": [10, np.nan, 15, np.nan, 20, np.nan, 25]\n",
        "}\n",
        "time_series_df = pd.DataFrame(time_series_with_gaps)\n",
        "time_series_df['Value'] = time_series_df['Value'].interpolate()\n",
        "print(time_series_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47WmZDVes1a",
        "outputId": "2aa99486-0c9c-4220-8138-26ca249cdbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Date  Value\n",
            "0 2023-01-01   10.0\n",
            "1 2023-01-02   12.5\n",
            "2 2023-01-03   15.0\n",
            "3 2023-01-04   17.5\n",
            "4 2023-01-05   20.0\n",
            "5 2023-01-06   22.5\n",
            "6 2023-01-07   25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "time_series_with_gaps = {\n",
        "    \"Date\": pd.date_range(start=\"2023-01-01\", periods=7),\n",
        "    \"Value\": [10, np.nan, 15, np.nan, 20, np.nan, 25]\n",
        "}\n",
        "df = pd.DataFrame(time_series_with_gaps)\n",
        "print(\"Original Time-Series with Missing Values:\")\n",
        "print(df)\n",
        "df['Value'] = df['Value'].interpolate(method='linear')\n",
        "print(\"\\nTime-Series After Interpolation:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stYitR7neycr",
        "outputId": "6d2c9495-3dc6-4ee4-c7ae-076dabad60ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Time-Series with Missing Values:\n",
            "        Date  Value\n",
            "0 2023-01-01   10.0\n",
            "1 2023-01-02    NaN\n",
            "2 2023-01-03   15.0\n",
            "3 2023-01-04    NaN\n",
            "4 2023-01-05   20.0\n",
            "5 2023-01-06    NaN\n",
            "6 2023-01-07   25.0\n",
            "\n",
            "Time-Series After Interpolation:\n",
            "        Date  Value\n",
            "0 2023-01-01   10.0\n",
            "1 2023-01-02   12.5\n",
            "2 2023-01-03   15.0\n",
            "3 2023-01-04   17.5\n",
            "4 2023-01-05   20.0\n",
            "5 2023-01-06   22.5\n",
            "6 2023-01-07   25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### Conclusion\n",
        " In this session, we covered strategies to handle missing data, including identifying missing values, filling them with meaningful replacements, dropping incomplete rows/columns, and using interpolation for continuous data.\n"
      ],
      "metadata": {
        "id": "861ZpabK-vz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Merging and Aggregations\n",
        " ### Goal:\n",
        " Learn how to combine datasets and summarize data effectively.\n"
      ],
      "metadata": {
        "id": "39N06dDt-9tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "M2Yfz1j8_CCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        " ### 1. Merging Datasets\n",
        " Merging combines two datasets based on a common key.\n",
        "\n",
        " #### Example: Perform an Inner Join\n",
        "Create two sample DataFrames"
      ],
      "metadata": {
        "id": "B2AM0KhL_C6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_customers = pd.DataFrame({\n",
        "    \"CustomerID\": [1, 2, 3, 4],\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"]\n",
        "})\n",
        "\n",
        "df_purchases = pd.DataFrame({\n",
        "    \"CustomerID\": [1, 2, 4, 5],\n",
        "    \"PurchaseAmount\": [250, 400, 150, 300]\n",
        "})\n",
        "\n",
        "print(\"Customers DataFrame:\")\n",
        "print(df_customers)\n",
        "\n",
        "print(\"\\nPurchases DataFrame:\")\n",
        "print(df_purchases)"
      ],
      "metadata": {
        "id": "zynC1ArT_Lw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcd395e-fbf7-4e83-a16e-d50fcd2d9bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers DataFrame:\n",
            "   CustomerID     Name\n",
            "0           1    Alice\n",
            "1           2      Bob\n",
            "2           3  Charlie\n",
            "3           4    David\n",
            "\n",
            "Purchases DataFrame:\n",
            "   CustomerID  PurchaseAmount\n",
            "0           1             250\n",
            "1           2             400\n",
            "2           4             150\n",
            "3           5             300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform an inner join on \"CustomerID\"\n",
        "df_inner_join = pd.merge(df_customers, df_purchases, on=\"CustomerID\", how=\"inner\")\n",
        "print(\"\\nInner Join Result:\")\n",
        "print(df_inner_join)"
      ],
      "metadata": {
        "id": "NsXdLlaG_ijV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82d2f41-70bc-4d47-a76d-fa0d60d8de12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inner Join Result:\n",
            "   CustomerID   Name  PurchaseAmount\n",
            "0           1  Alice             250\n",
            "1           2    Bob             400\n",
            "2           4  David             150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### Example: Perform an Outer Join\n",
        "df_outer_join = pd.merge(df_customers, df_purchases, on=\"CustomerID\", how=\"outer\")\n",
        "print(\"\\nOuter Join Result:\")\n",
        "print(df_outer_join)\n"
      ],
      "metadata": {
        "id": "SCQuqWqt_Xu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11cc60ad-e7b1-48bd-da52-68e4f8a239fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Outer Join Result:\n",
            "   CustomerID     Name  PurchaseAmount\n",
            "0           1    Alice           250.0\n",
            "1           2      Bob           400.0\n",
            "2           3  Charlie             NaN\n",
            "3           4    David           150.0\n",
            "4           5      NaN           300.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 2. Concatenating Datasets\n",
        " Concatenating combines datasets either vertically (rows) or horizontally (columns).\n",
        "\n",
        " #### Example: Vertical Concatenation"
      ],
      "metadata": {
        "id": "horhhl3t_8GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sales_q1 = pd.DataFrame({\n",
        "    \"Month\": [\"Jan\", \"Feb\", \"Mar\"],\n",
        "    \"Sales\": [300, 400, 500]\n",
        "})\n",
        "\n",
        "df_sales_q2 = pd.DataFrame({\n",
        "    \"Month\": [\"Apr\", \"May\", \"Jun\"],\n",
        "    \"Sales\": [450, 350, 600]\n",
        "})\n",
        "\n",
        "print(\"\\nQ1 Sales DataFrame:\")\n",
        "print(df_sales_q1)\n",
        "\n",
        "print(\"\\nQ2 Sales DataFrame:\")\n",
        "print(df_sales_q2)"
      ],
      "metadata": {
        "id": "xyYH-dCDAAEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6564f63b-0077-443e-c1e9-376d4b4fcd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q1 Sales DataFrame:\n",
            "  Month  Sales\n",
            "0   Jan    300\n",
            "1   Feb    400\n",
            "2   Mar    500\n",
            "\n",
            "Q2 Sales DataFrame:\n",
            "  Month  Sales\n",
            "0   Apr    450\n",
            "1   May    350\n",
            "2   Jun    600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate vertically\n",
        "df_vertical_concat = pd.concat([df_sales_q1, df_sales_q2], ignore_index=True)\n",
        "print(\"\\nVertical Concatenation Result:\")\n",
        "print(df_vertical_concat)"
      ],
      "metadata": {
        "id": "7Eqcok9pAB9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f196e99-de9d-4e7b-fbe5-28ab0c421301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vertical Concatenation Result:\n",
            "  Month  Sales\n",
            "0   Jan    300\n",
            "1   Feb    400\n",
            "2   Mar    500\n",
            "3   Apr    450\n",
            "4   May    350\n",
            "5   Jun    600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### Example: Horizontal Concatenation\n",
        "df_store_info = pd.DataFrame({\n",
        "    \"StoreID\": [1, 2],\n",
        "    \"Location\": [\"Downtown\", \"Suburbs\"]\n",
        "})\n",
        "\n",
        "df_store_sales = pd.DataFrame({\n",
        "    \"StoreID\": [1, 2],\n",
        "    \"TotalSales\": [1000, 1500]\n",
        "})\n",
        "\n",
        "print(\"\\nStore Information DataFrame:\")\n",
        "print(df_store_info)\n",
        "\n",
        "print(\"\\nStore Sales DataFrame:\")\n",
        "print(df_store_sales)\n"
      ],
      "metadata": {
        "id": "wlQHjAbdAEte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9e080c-afd0-4dd6-9e52-f257fd8b0f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Store Information DataFrame:\n",
            "   StoreID  Location\n",
            "0        1  Downtown\n",
            "1        2   Suburbs\n",
            "\n",
            "Store Sales DataFrame:\n",
            "   StoreID  TotalSales\n",
            "0        1        1000\n",
            "1        2        1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate horizontally\n",
        "df_horizontal_concat = pd.concat([df_store_info, df_store_sales], axis=1)\n",
        "print(\"\\nHorizontal Concatenation Result:\")\n",
        "print(df_horizontal_concat)"
      ],
      "metadata": {
        "id": "vKS9duuhAGkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ffa331-8bba-44dc-d44a-44cf30a52d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Horizontal Concatenation Result:\n",
            "   StoreID  Location  StoreID  TotalSales\n",
            "0        1  Downtown        1        1000\n",
            "1        2   Suburbs        2        1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ---\n",
        " ### 3. Aggregations\n",
        " Aggregations summarize data based on specific criteria.\n",
        "\n",
        " #### Example: Group Data by a Column"
      ],
      "metadata": {
        "id": "86wwONv2AI14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_employees = pd.DataFrame({\n",
        "    \"Department\": [\"HR\", \"Finance\", \"HR\", \"IT\", \"Finance\", \"IT\"],\n",
        "    \"Salary\": [50000, 70000, 60000, 80000, 75000, 85000]\n",
        "})\n",
        "\n",
        "print(\"\\nEmployees DataFrame:\")\n",
        "print(df_employees)\n"
      ],
      "metadata": {
        "id": "4LC3HTvpAOyA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cefdda4-c070-4809-a81e-0c18db0604e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Employees DataFrame:\n",
            "  Department  Salary\n",
            "0         HR   50000\n",
            "1    Finance   70000\n",
            "2         HR   60000\n",
            "3         IT   80000\n",
            "4    Finance   75000\n",
            "5         IT   85000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by \"Department\" and calculate mean salary\n",
        "df_grouped = df_employees.groupby(\"Department\")[\"Salary\"].mean().reset_index()\n",
        "print(\"\\nAverage Salary by Department:\")\n",
        "print(df_grouped)\n"
      ],
      "metadata": {
        "id": "FVtP1e9dAQif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3aad7fb-5693-4ddc-91a3-998e5ba1c2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Salary by Department:\n",
            "  Department   Salary\n",
            "0    Finance  72500.0\n",
            "1         HR  55000.0\n",
            "2         IT  82500.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #### Example: Custom Aggregation\n",
        " Aggregate multiple statistics"
      ],
      "metadata": {
        "id": "WcbHv100ATrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_agg = df_employees.groupby(\"Department\")[\"Salary\"].agg([\"sum\", \"mean\", \"max\"]).reset_index()\n",
        "print(\"\\nAggregated Salary Statistics by Department:\")\n",
        "print(df_agg)"
      ],
      "metadata": {
        "id": "7eXL_zU_AWvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfecb55a-117a-434e-8fb4-31cd72ec994c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregated Salary Statistics by Department:\n",
            "  Department     sum     mean    max\n",
            "0    Finance  145000  72500.0  75000\n",
            "1         HR  110000  55000.0  60000\n",
            "2         IT  165000  82500.0  85000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        " ### Practice Exercises\n",
        "\n",
        " #### Exercise 1: Merge Two DataFrames\n",
        " - Create a DataFrame with customer details and another with purchase history.\n",
        " - Perform a left join to retain all customer details.\n"
      ],
      "metadata": {
        "id": "OpcNtU3mAY4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_customer_details = pd.DataFrame({\n",
        "    \"CustomerID\": [1, 2, 3, 4],\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"]\n",
        "})\n",
        "df_purchase_history = pd.DataFrame({\n",
        "    \"CustomerID\": [2, 4, 5],\n",
        "    \"TotalPurchases\": [5, 3, 7]\n",
        "})\n",
        "df_merged = pd.merge(df_customer_details, df_purchase_history, on=\"CustomerID\", how=\"left\")\n",
        "print(df_merged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOSq0eWykTWL",
        "outputId": "3b628bdc-6ccc-44ae-8b15-b3d1d6f20547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID     Name  TotalPurchases\n",
            "0           1    Alice             NaN\n",
            "1           2      Bob             5.0\n",
            "2           3  Charlie             NaN\n",
            "3           4    David             3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_customer_details = pd.DataFrame({\n",
        "    \"CustomerID\": [1, 2, 3, 4],\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"]\n",
        "})\n",
        "df_purchase_history = pd.DataFrame({\n",
        "    \"CustomerID\": [2, 4, 5],\n",
        "    \"TotalPurchases\": [5, 3, 7]\n",
        "})\n",
        "merged_df = pd.merge(df_customer_details, df_purchase_history, on=\"CustomerID\", how=\"left\")\n",
        "print(\"Merged DataFrame (left Join):\")\n",
        "print(merged_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSLgrXmZkieh",
        "outputId": "2807b5e5-a6e8-4ab6-9f3e-db6a6ded3001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged DataFrame (left Join):\n",
            "   CustomerID     Name  TotalPurchases\n",
            "0           1    Alice             NaN\n",
            "1           2      Bob             5.0\n",
            "2           3  Charlie             NaN\n",
            "3           4    David             3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_customer_details = pd.DataFrame({\n",
        "    \"CustomerID\": [1, 2, 3, 4],\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"]\n",
        "})\n",
        "\n",
        "df_purchase_history = pd.DataFrame({\n",
        "    \"CustomerID\": [2, 4, 5],\n",
        "    \"TotalPurchases\": [5, 3, 7]\n",
        "})"
      ],
      "metadata": {
        "id": "nf17Kjj7AdR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform left join\n",
        "df_left_join = pd.merge(df_customer_details, df_purchase_history, on=\"CustomerID\", how=\"left\")\n",
        "print(\"\\nLeft Join Result:\")\n",
        "print(df_left_join)"
      ],
      "metadata": {
        "id": "gGwDUaANAfG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0627f6c6-f4da-44cd-ab8c-fa952e4a8e78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Left Join Result:\n",
            "   CustomerID     Name  TotalPurchases\n",
            "0           1    Alice             NaN\n",
            "1           2      Bob             5.0\n",
            "2           3  Charlie             NaN\n",
            "3           4    David             3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #### Exercise 2: Group and Calculate Average\n",
        " - Group the Titanic dataset by \"class\" and calculate the average \"fare\"."
      ],
      "metadata": {
        "id": "HZWEKEepAg_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "titanic = sns.load_dataset('titanic')\n",
        "avg_fare_by_class = titanic.groupby('class') ['fare'].mean()\n",
        "print(avg_fare_by_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE07yi6oliVC",
        "outputId": "f09a2c02-5d32-4e49-e639-6b4c823fb088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class\n",
            "First     84.154687\n",
            "Second    20.662183\n",
            "Third     13.675550\n",
            "Name: fare, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-9f4478bec407>:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  avg_fare_by_class = titanic.groupby('class') ['fare'].mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "average_fare_by_class = titanic.groupby(\"class\")[\"fare\"].mean()\n",
        "print(average_fare_by_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg1YaLj4luo7",
        "outputId": "7bafbd82-462f-4fed-fcc3-e99aad29260f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class\n",
            "First     84.154687\n",
            "Second    20.662183\n",
            "Third     13.675550\n",
            "Name: fare, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-6138583b585d>:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  average_fare_by_class = titanic.groupby(\"class\")[\"fare\"].mean()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "print(\"\\nTitanic Dataset:\")\n",
        "print(titanic.head())\n",
        "\n",
        "# Group by \"class\" and calculate average \"fare\"\n",
        "df_class_fare = titanic.groupby(\"class\")[\"fare\"].mean().reset_index()\n",
        "print(\"\\nAverage Fare by Class:\")\n",
        "print(df_class_fare)"
      ],
      "metadata": {
        "id": "z9voLg2NAk80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " #### Exercise 3: Concatenate and Sort\n",
        " - Create two DataFrames with sales data.\n",
        " - Concatenate them and sort by \"Sales\"."
      ],
      "metadata": {
        "id": "xlZp_UvLAoAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_sales_part1 = pd.DataFrame({\n",
        "    \"Product\": [\"A\", \"B\", \"C\"],\n",
        "    \"Sales\": [200, 150, 300]\n",
        "})\n",
        "df_sales_part2 = pd.DataFrame({\n",
        "    \"Product\": [\"D\", \"E\", \"F\"],\n",
        "    \"Sales\": [250, 400, 100]\n",
        "})\n",
        "df_combined = pd.concat([df_sales_part1, df_sales_part2])\n",
        "df_sorted = df_combined.sort_values(by=\"Sales\")\n",
        "print(df_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uxj4JvvnDnD",
        "outputId": "d1e058e3-af85-4952-debf-d7bbf5d2f038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Product  Sales\n",
            "2       F    100\n",
            "1       B    150\n",
            "0       A    200\n",
            "0       D    250\n",
            "2       C    300\n",
            "1       E    400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sales_part1 = pd.DataFrame({\n",
        "    \"Product\": [\"A\", \"B\", \"C\"],\n",
        "    \"Sales\": [200, 150, 300]\n",
        "})\n",
        "\n",
        "df_sales_part2 = pd.DataFrame({\n",
        "    \"Product\": [\"D\", \"E\", \"F\"],\n",
        "    \"Sales\": [250, 400, 100]\n",
        "})"
      ],
      "metadata": {
        "id": "xfKqCWxmArmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Concatenate and sort\n",
        "df_sales_combined = pd.concat([df_sales_part1, df_sales_part2], ignore_index=True).sort_values(\"Sales\")\n",
        "print(\"\\nConcatenated and Sorted Sales DataFrame:\")\n",
        "print(df_sales_combined)\n"
      ],
      "metadata": {
        "id": "np0zx2wMXVRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78ee607-1642-4e50-8e48-3faba522ae72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Concatenated and Sorted Sales DataFrame:\n",
            "  Product  Sales\n",
            "5       F    100\n",
            "1       B    150\n",
            "0       A    200\n",
            "3       D    250\n",
            "2       C    300\n",
            "4       E    400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_sales_part1 = pd.DataFrame({\n",
        "    \"Product\": [\"A\", \"B\", \"C\"],\n",
        "    \"Sales\": [200, 150, 300]\n",
        "})\n",
        "df_sales_part2 = pd.DataFrame({\n",
        "    \"Product\": [\"D\", \"E\", \"F\"],\n",
        "    \"Sales\": [250, 400, 100]\n",
        "})\n",
        "df_sales = pd.concat([df_sales_part1, df_sales_part2], ignore_index=True)\n",
        "df_sales_sorted = df_sales.sort_values(by='Sales', ascending=False)\n",
        "print(df_sales_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu2D3RfynPow",
        "outputId": "b7923225-4b30-4c30-a41f-566f6e9d8ad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Product  Sales\n",
            "4       E    400\n",
            "2       C    300\n",
            "3       D    250\n",
            "0       A    200\n",
            "1       B    150\n",
            "5       F    100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---\n",
        " ### Conclusion\n",
        " In this session, we learned how to merge datasets using joins, concatenate datasets, and perform aggregations to summarize data effectively.\n"
      ],
      "metadata": {
        "id": "pB3uXmy6AugN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Project: Data Manipulation with Pandas  \n",
        "\n",
        "**Goal:**  \n",
        "Apply the concepts of data cleaning, merging, grouping, and aggregations in a hands-on project to simulate real-world data analysis scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "### **Steps to Be Followed**\n",
        "\n",
        "1. **Load the Dataset**  \n",
        "   - Use a dataset of your choice (e.g., **Retail Sales** or **COVID-19 Cases**). You can either load a dataset from a library like `seaborn` or use a CSV file hosted online.\n",
        "\n",
        "2. **Clean the Data**  \n",
        "   - Identify missing values and handle them using techniques such as replacing with the mean, median, or mode.\n",
        "   - Drop unnecessary or irrelevant columns.\n",
        "   - Rename columns to follow a consistent naming convention.\n",
        "\n",
        "3. **Enhance the Data**  \n",
        "   - Add a new column derived from existing data (e.g., categorize numeric values into ranges or calculate a ratio).\n",
        "   - Create a synthetic dataset and merge it with the cleaned dataset.\n",
        "\n",
        "4. **Analyze the Data**  \n",
        "   - Group the data by a categorical column and compute summary statistics (e.g., average sales by region, total cases by country).\n",
        "   - Perform aggregations to gain insights.\n",
        "\n",
        "5. **Save the Final Dataset**  \n",
        "   - Export the cleaned and processed dataset to a CSV file for future use.\n",
        "\n",
        "6. **Practice Questions**  \n",
        "   - Compute additional insights like averages, sums, or percentages.\n",
        "   - Visualize relationships in the data using basic plots.\n",
        "\n",
        "---\n",
        "\n",
        "### **Alternative Dataset: Retail Sales Dataset**  \n",
        "Use a **Retail Sales dataset** containing columns like:  \n",
        "- `Product_ID`, `Store_ID`, `Category`, `Sub-Category`, `Region`, `Sales`, `Quantity`, `Discount`, and `Profit`.  \n",
        "\n",
        "**Tasks to Perform:**  \n",
        "1. Handle missing values in `Sales` or `Profit` columns.  \n",
        "2. Add a new column like `Profit Margin (%) = (Profit / Sales) * 100`.  \n",
        "3. Merge with a synthetic dataset containing `Store_ID` and `Store Manager Name`.  \n",
        "4. Group data by `Region` and calculate total sales and average profit margin.  \n",
        "5. Save the processed dataset to `cleaned_retail_sales.csv`.  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "QtQl5xVeBUMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Final Project: Data Manipulation with Pandas\n",
        "# ## Goal:\n",
        "# Apply the concepts of data cleaning, merging, grouping, and aggregations.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---\n",
        "# ### 1. Create Dummy Retail Sales Dataset\n",
        "# Retail dataset with missing values and inconsistent column names\n",
        "retail_data = pd.DataFrame({\n",
        "    \"Product_ID\": [101, 102, 103, 104, 105],\n",
        "    \"Store_ID\": [1, 2, 2, 3, np.nan],\n",
        "    \"Category\": [\"Electronics\", \"Clothing\", \"Clothing\", \"Groceries\", \"Electronics\"],\n",
        "    \"Sub_Category\": [\"Phones\", \"Shirts\", \"Pants\", \"Fruits\", \"Laptops\"],\n",
        "    \"Region\": [\"North\", \"South\", \"South\", \"West\", np.nan],\n",
        "    \"Sales\": [5000, 2000, np.nan, 800, 1500],\n",
        "    \"Quantity\": [10, 5, 8, 12, np.nan],\n",
        "    \"Profit\": [800, 300, 200, 50, 200],\n",
        "    \"Discount (%)\": [10, 5, 0, 2, 5]\n",
        "})\n",
        "\n",
        "print(\"Initial Dataset:\")\n",
        "print(retail_data)\n",
        "\n",
        "# ---\n",
        "# ### 2. Clean the Data\n",
        "# #### Handle Missing Values\n",
        "# Fill missing \"Sales\" values with the median of the column\n",
        "median_sales = retail_data[\"Sales\"].median()\n",
        "retail_data[\"Sales\"] = retail_data[\"Sales\"].fillna(median_sales)\n",
        "\n",
        "# Fill missing \"Store_ID\" with the most frequent Store_ID (mode)\n",
        "mode_store_id = retail_data[\"Store_ID\"].mode()[0]\n",
        "retail_data[\"Store_ID\"] = retail_data[\"Store_ID\"].fillna(mode_store_id)\n",
        "\n",
        "# Fill missing \"Region\" with a placeholder\n",
        "retail_data[\"Region\"] = retail_data[\"Region\"].fillna(\"Unknown\")\n",
        "\n",
        "# Replace missing \"Quantity\" with the column mean\n",
        "mean_quantity = retail_data[\"Quantity\"].mean()\n",
        "retail_data[\"Quantity\"] = retail_data[\"Quantity\"].fillna(mean_quantity)\n",
        "\n",
        "print(\"\\nDataset After Handling Missing Values:\")\n",
        "print(retail_data)\n",
        "\n",
        "# #### Rename Columns\n",
        "retail_data = retail_data.rename(columns={\"Discount (%)\": \"Discount_Percentage\"})\n",
        "\n",
        "print(\"\\nDataset After Renaming Columns:\")\n",
        "print(retail_data)\n",
        "\n",
        "# ---\n",
        "# ### 3. Enhance the Data\n",
        "# #### Add a New Column: Profit Margin\n",
        "retail_data[\"Profit_Margin (%)\"] = (retail_data[\"Profit\"] / retail_data[\"Sales\"]) * 100\n",
        "print(\"\\nDataset with 'Profit_Margin (%)':\")\n",
        "print(retail_data)\n",
        "\n",
        "# #### Create a Synthetic Dataset and Merge\n",
        "# Synthetic dataset with Store_ID and Manager names\n",
        "manager_data = pd.DataFrame({\n",
        "    \"Store_ID\": [1, 2, 3],\n",
        "    \"Store_Manager\": [\"Alice\", \"Bob\", \"Charlie\"]\n",
        "})\n",
        "\n",
        "# Merge the two datasets\n",
        "retail_data = pd.merge(retail_data, manager_data, on=\"Store_ID\", how=\"left\")\n",
        "print(\"\\nDataset After Merging with Synthetic Data:\")\n",
        "print(retail_data)\n",
        "\n",
        "# ---\n",
        "# ### 4. Analyze the Data\n",
        "# #### Group Data by Region and Calculate Summary Statistics\n",
        "region_summary = retail_data.groupby(\"Region\").agg(\n",
        "    Total_Sales=(\"Sales\", \"sum\"),\n",
        "    Avg_Profit_Margin=(\"Profit_Margin (%)\", \"mean\")\n",
        ").reset_index()\n",
        "\n",
        "print(\"\\nSummary Statistics by Region:\")\n",
        "print(region_summary)\n",
        "\n",
        "# ---\n",
        "# ### 5. Save the Cleaned Dataset\n",
        "output_file = \"cleaned_retail_sales.csv\"\n",
        "retail_data.to_csv(output_file, index=False)\n",
        "print(f\"\\nCleaned dataset saved to {output_file}!\")\n",
        "\n",
        "# ---\n",
        "# ### Practice Questions\n",
        "# 1. Calculate the total quantity sold by Category.\n",
        "category_summary = retail_data.groupby(\"Category\")[\"Quantity\"].sum().reset_index()\n",
        "print(\"\\nTotal Quantity Sold by Category:\")\n",
        "print(category_summary)\n",
        "\n",
        "# 2. Find the Store with the highest total Sales.\n",
        "store_sales_summary = retail_data.groupby(\"Store_ID\")[\"Sales\"].sum().reset_index()\n",
        "store_with_max_sales = store_sales_summary.loc[store_sales_summary[\"Sales\"].idxmax()]\n",
        "print(f\"\\nStore with Highest Total Sales:\\n{store_with_max_sales}\")\n"
      ],
      "metadata": {
        "id": "ELFTBf6ZBYgp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}